{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models.ad_llava import ADLlavaModel\n",
    "from models.condition import conditional_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_LENGTH = 1024\n",
    "\n",
    "model_path = \" \".format(MAX_LENGTH)\n",
    "lora_path = \" \".format(MAX_LENGTH)\n",
    "\n",
    "model = ADLlavaModel.from_pretrained(model_path)\n",
    "processor = AutoProcessor.from_pretrained(\"\")\n",
    "from peft import PeftConfig, PeftModel\n",
    "\n",
    "config = PeftConfig.from_pretrained(lora_path)\n",
    "lora_model = PeftModel.from_pretrained(model, lora_path, attn_implementation=\"flash_attention_2\")\n",
    "model = lora_model.to('cuda').to(torch.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeedfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('', 'r') as f:\n",
    "    test_datas = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c680817",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images = []\n",
    "for test_data in tqdm(test_datas):\n",
    "    image = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        image.append(Image.open(image_path).convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16820f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from models.condition import conditional_prompt\n",
    "\n",
    "label_dict = {0: 'CN', 1: 'MCI', 2: 'AD'}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for test_data in tqdm(test_datas):\n",
    "    true_mri_label = test_data['mri_label']\n",
    "    true_pet_label = test_data['pet_label']\n",
    "    image_paths = test_data['image']\n",
    "    for conversation in test_data['conversations']:\n",
    "        if conversation['from'] == 'USER':\n",
    "            question = conversation['value']\n",
    "        if conversation['from'] == 'ASSISTANT':\n",
    "            answer = conversation['value']\n",
    "    # print(image_paths)\n",
    "    image = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        image.append(Image.open(image_path).convert(\"RGB\"))\n",
    "\n",
    "    prompts = f\"{question}\\nASSISTANT:\"\n",
    "    # print(prompts)\n",
    "\n",
    "    processed_example = processor(text = prompts, padding=\"max_length\", truncation=True, \\\n",
    "                                        max_length=MAX_LENGTH, images=image,return_tensors=\"pt\")\n",
    "\n",
    "    inputs = {}\n",
    "    inputs['pixel_values'] = torch.FloatTensor(processed_example['pixel_values'].unsqueeze(0)).to('cuda')\n",
    "    inputs['input_ids'] = torch.LongTensor(processed_example['input_ids']).to('cuda')\n",
    "    inputs['labels'] = None\n",
    "    inputs['mri_label'] = None\n",
    "    inputs['pet_label'] = None\n",
    "    inputs['return_cls_only'] = True\n",
    "\n",
    "\n",
    "    loss, mri_logits, pet_logits, image_feature, ad_image_feature = model.forward(**inputs)\n",
    "    mri_pred_level = mri_logits[0].argmax().item()\n",
    "    pet_pred_level = pet_logits[0].argmax().item()\n",
    "\n",
    "    additional_prompt = conditional_prompt(mri_pred_level,pet_pred_level)\n",
    "\n",
    "    system_prompts = f\"You are a expert in the field of Alzheimer's Disease diagnosis. Your task is to diagnose based on the image information, demographic information, and neuropsychological scales data. Please give the final clinical answer.\"\n",
    "    text = system_prompts + \"\\n<image>\\nUser:\" + additional_prompt + prompts\n",
    "\n",
    "    processed_example = processor(text, padding=\"max_length\", truncation=True, \\\n",
    "                                    max_length=MAX_LENGTH, images=image,return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "    inputs['input_ids'] = torch.LongTensor(processed_example['input_ids']).to('cuda')\n",
    "\n",
    "    output = model.generate(**inputs, max_new_tokens=1024)\n",
    "    generated_text = processor.batch_decode(output, skip_special_tokens=True)\n",
    "    answer = generated_text.split(\"ASSISTANT:\")[-1]\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"程序运行时间：{elapsed_time}秒\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
